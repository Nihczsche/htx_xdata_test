{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTX xData Test cv-hotword-similarity-5b Python Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zchin/miniconda3/envs/htx_xdata_test/lib/python3.12/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n",
      ".gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 5.77MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 270/270 [00:00<00:00, 810kB/s]\n",
      "2_Dense/config.json: 100%|██████████| 116/116 [00:00<00:00, 434kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 3.15M/3.15M [00:00<00:00, 11.7MB/s]\n",
      "README.md: 100%|██████████| 66.3k/66.3k [00:00<00:00, 53.7MB/s]\n",
      "config.json: 100%|██████████| 1.53k/1.53k [00:00<00:00, 13.2MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 249kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.34G/1.34G [01:56<00:00, 11.5MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 249kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 4.58MB/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 12.5MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.42M/2.42M [00:00<00:00, 4.72MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 2.41k/2.41k [00:00<00:00, 20.8MB/s]\n",
      "modules.json: 100%|██████████| 461/461 [00:00<00:00, 1.90MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>finetuned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-dev/sample-000000.mp3</td>\n",
       "      <td>be careful with your prognostications said the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE CAREFUL WITH YOUR PROGNOSTICATIONS SAID THE...</td>\n",
       "      <td>BE CAREFUL WITH YOUR PROGNOSTICATIONS SAID THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-dev/sample-000001.mp3</td>\n",
       "      <td>then why should they be surprised when they se...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THEN WHY SHOULD THEY BE SURPRISED WHEN THEY SE...</td>\n",
       "      <td>THEN WHY SHOULD THEY BE SURPRISED WHEN THEY SE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-dev/sample-000002.mp3</td>\n",
       "      <td>a young arab also loaded down with baggage ent...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A YOUNG ARAB ALSO LOADED DOWN WITH BAGGAGE ENT...</td>\n",
       "      <td>A YOUNG ARAB ALSO LOADED DOWN WITH BAGGAGE ENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-dev/sample-000003.mp3</td>\n",
       "      <td>i thought that everything i owned would be des...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I FELT THAT EVERYTHING I OWNED WOULD BE DESTROYED</td>\n",
       "      <td>I THOUGHT THAT EVERYTHING I OWNED WOULD BE DES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-dev/sample-000004.mp3</td>\n",
       "      <td>he moved about invisible but everyone could he...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fourties</td>\n",
       "      <td>female</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HE MOVED ABOUT INVISIBLE BUT EVERY ONE COULD H...</td>\n",
       "      <td>HE MOVED ABOUT INVISIBLE BUT EVERYONE COULD HE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0  cv-valid-dev/sample-000000.mp3   \n",
       "1  cv-valid-dev/sample-000001.mp3   \n",
       "2  cv-valid-dev/sample-000002.mp3   \n",
       "3  cv-valid-dev/sample-000003.mp3   \n",
       "4  cv-valid-dev/sample-000004.mp3   \n",
       "\n",
       "                                                text  up_votes  down_votes  \\\n",
       "0  be careful with your prognostications said the...         1           0   \n",
       "1  then why should they be surprised when they se...         2           0   \n",
       "2  a young arab also loaded down with baggage ent...         2           0   \n",
       "3  i thought that everything i owned would be des...         3           0   \n",
       "4  he moved about invisible but everyone could he...         1           0   \n",
       "\n",
       "        age  gender   accent  duration  \\\n",
       "0       NaN     NaN      NaN       NaN   \n",
       "1       NaN     NaN      NaN       NaN   \n",
       "2       NaN     NaN      NaN       NaN   \n",
       "3       NaN     NaN      NaN       NaN   \n",
       "4  fourties  female  england       NaN   \n",
       "\n",
       "                                      generated_text  \\\n",
       "0  BE CAREFUL WITH YOUR PROGNOSTICATIONS SAID THE...   \n",
       "1  THEN WHY SHOULD THEY BE SURPRISED WHEN THEY SE...   \n",
       "2  A YOUNG ARAB ALSO LOADED DOWN WITH BAGGAGE ENT...   \n",
       "3  I FELT THAT EVERYTHING I OWNED WOULD BE DESTROYED   \n",
       "4  HE MOVED ABOUT INVISIBLE BUT EVERY ONE COULD H...   \n",
       "\n",
       "                                      finetuned_text  \n",
       "0  BE CAREFUL WITH YOUR PROGNOSTICATIONS SAID THE...  \n",
       "1  THEN WHY SHOULD THEY BE SURPRISED WHEN THEY SE...  \n",
       "2  A YOUNG ARAB ALSO LOADED DOWN WITH BAGGAGE ENT...  \n",
       "3  I THOUGHT THAT EVERYTHING I OWNED WOULD BE DES...  \n",
       "4  HE MOVED ABOUT INVISIBLE BUT EVERYONE COULD HE...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "cv_dev_metadata = pd.read_csv(os.path.join('..', 'asr-train', 'cv-valid-dev.csv'))\n",
    "cv_dev_metadata['finetuned_text'] = cv_dev_metadata['finetuned_text'].astype(str)\n",
    "\n",
    "cv_dev_metadata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the hotword and text to embeddings, and use cosine similarity to generate a similarity score between phrase and sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72322273 0.8924132  0.8676585 ]\n",
      " [0.7357803  0.79125535 0.80064064]\n",
      " [0.7337803  0.7572438  0.79558104]\n",
      " ...\n",
      " [0.7480864  0.8030087  0.7612227 ]\n",
      " [0.7127923  0.7348097  0.75321025]\n",
      " [0.73576105 0.74254346 0.7491277 ]]\n",
      "[0.72322273 0.8924132  0.8676585 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "hotword_list = [\"destroy\", \"be careful\", \"stranger\"]\n",
    "\n",
    "# Use capitalize as the encodings behave differently in all uppercase, and provided examples use capitalize.\n",
    "sentences_a = [['Represent the sentence to match: ', s.capitalize()] for s in cv_dev_metadata[\"finetuned_text\"]]\n",
    "sentences_b = [['Represent the phrase to find: ', hotword] for hotword in hotword_list]\n",
    "embeddings_a = model.encode(sentences_a)\n",
    "embeddings_b = model.encode(sentences_b)\n",
    "similarities = cosine_similarity(embeddings_a,embeddings_b)\n",
    "\n",
    "print(similarities)\n",
    "print(similarities[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our dataset, we know from cv-hotword-5a that there are some samples which have phrases exactly matching the hotwords. These samples can be labelled as true in similarity, and we can use these labelled samples to provide a good estimate on the minimum similarity score for a particular sample to be considered similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'destroy': 0.85274625, 'be careful': 0.8924132, 'stranger': 0.81990176}\n"
     ]
    }
   ],
   "source": [
    "min_similarity_score = {}\n",
    "\n",
    "for idx, hotword in enumerate(hotword_list):\n",
    "    cv_dev_exactmatch_generated = cv_dev_metadata[cv_dev_metadata['finetuned_text'].str.contains(hotword.upper(), na=False)]\n",
    "    similarity_scores = []\n",
    "    for row_idx, row in enumerate(cv_dev_exactmatch_generated.index):\n",
    "        similarity_scores.append(similarities[row][idx])\n",
    "    \n",
    "    min_similarity_score[hotword] = min(similarity_scores)\n",
    "\n",
    "print(min_similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through all the similarity scores and find all entries that are equal to or greater than the similarity score of each exact match sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of similar entries: 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finetuned_text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>AND THE GIRL POINTED TO THE SOUTH INDICATING THAT IT WAS THERE THE STRANGE MAN LIVED</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>THIS WAS THE STRANGEST OF ALL THINGS THAT EVER CAME TO EARTH FROM OUTER SPACE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>STRANGE IMAGES PASSED THROUGH MY MIND</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>THE GUY THOUGHT HE WAS A LUNATIC AT LARGE AND MADE AN UNSUCCESSFUL ATTEMPT TO STOP HIM</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>I DON'T LIKE PEOPLE TO DO THAT BECAUSE THE SHEEP ARE AFRAID OF STRANGERS</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I THOUGHT THAT EVERYTHING I OWNED WOULD BE DESTROYED</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>SANDRA READ ALOUD THE STRANGE EXCERT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>HE DIDN'T KNOW THE MAN YET BUT HIS PRACTICED EYE WOULD RECOGNIZE HIM WHEN HE APPEARED</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>STRANGE IMAGES PASSED THROUGH MY MIND</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>HE DIDN'NT KNOW THE MAN YET BUT HIS PRACTICED EYE WOULD RECOGNIZE HIM WHEN HE APPEARED</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "boolean_list = []\n",
    "\n",
    "for similarity in similarities:\n",
    "    boolean_list.append(any([hotword_detect >= min_similarity_score[hotword_list[idx]] for idx, hotword_detect in enumerate(similarity)]))\n",
    "\n",
    "cv_dev_metadata[\"similarity\"] = boolean_list\n",
    "\n",
    "print(\"Number of similar entries: {}\".format(len(cv_dev_metadata[cv_dev_metadata[\"similarity\"] == True])))\n",
    "display(HTML(cv_dev_metadata[cv_dev_metadata[\"similarity\"] == True][[\"finetuned_text\", \"similarity\"]].sample(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dev_metadata.to_csv(\"cv-valid-dev.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htx_xdata_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
